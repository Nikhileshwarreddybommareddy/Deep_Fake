{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Frame Generator"
      ],
      "metadata": {
        "id": "D0oTPbjssJ1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import dlib\n",
        "\n",
        "def extract_faces_dlib(video_path, output_folder, label, max_frames=None):\n",
        "    # Initialize dlib's face detector (CNN-based)\n",
        "    face_detector = dlib.cnn_face_detection_model_v1(\"/content/drive/MyDrive/Project Data/Capstone_Deepfake/mmod_human_face_detector.dat\")\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "    count = 0\n",
        "    frame_number = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if max_frames is not None and frame_number >= max_frames:\n",
        "            break\n",
        "\n",
        "        # Convert frame to RGB as dlib expects RGB format\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Detect faces in the frame\n",
        "        detections = face_detector(rgb_frame, 1)\n",
        "\n",
        "        for detection in detections:\n",
        "            x, y, w, h = detection.rect.left(), detection.rect.top(), detection.rect.width(), detection.rect.height()\n",
        "\n",
        "            # Ensure the bounding box is within the frame\n",
        "            x, y, w, h = max(0, x), max(0, y), min(w, frame.shape[1] - x), min(h, frame.shape[0] - y)\n",
        "\n",
        "            # Extract the face region\n",
        "            face_img = frame[y:y+h, x:x+w]\n",
        "\n",
        "            if face_img.size == 0:\n",
        "                continue  # Skip empty images\n",
        "\n",
        "            resized_face = cv2.resize(face_img, (224, 224))\n",
        "\n",
        "            # Save the face image\n",
        "            output_path = os.path.join(output_folder, f\"{label}_{video_name}_face_{count}.jpg\")\n",
        "            cv2.imwrite(output_path, resized_face)\n",
        "            count += 1\n",
        "\n",
        "        frame_number += 1\n",
        "\n",
        "    cap.release()\n",
        "    # print(f\"Processed {video_name}, extracted {count} faces.\")\n"
      ],
      "metadata": {
        "id": "sHIchY9eUd98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "test = \"/content/drive/MyDrive/Project Data/Capstone_Deepfake/Celeb-real/\"\n",
        "og_folder = \"/content/drive/MyDrive/Project Data/Capstone_Deepfake/real_images_15/\"\n",
        "k = len(os.listdir(test))\n",
        "i=1\n",
        "for video_file in os.listdir(test):\n",
        "    video_path = os.path.join(test, video_file)\n",
        "    extract_faces_dlib(video_path, og_folder, label=\"real\",max_frames=15)\n",
        "    print(f'{i} out of {k} videos processed')\n",
        "    i+=1"
      ],
      "metadata": {
        "id": "pevnlflKQKbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "test = \"/content/drive/MyDrive/Project Data/Capstone_Deepfake/Celeb-synthesis/\"\n",
        "og_folder = \"/content/drive/MyDrive/Project Data/Capstone_Deepfake/fake_images_2/\"\n",
        "k = len(os.listdir(test))\n",
        "i=1\n",
        "for video_file in os.listdir(test):\n",
        "    video_path = os.path.join(test, video_file)\n",
        "    extract_faces_dlib(video_path, og_folder, label=\"fake\",max_frames=2)\n",
        "    print(f'{i} out of {k} videos processed')\n",
        "    i+=1"
      ],
      "metadata": {
        "id": "NFApCNycRWZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating CSV with Image names and labels"
      ],
      "metadata": {
        "id": "FUORVRwrsNc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(columns=['FileName', 'Label', 'ClassName'])\n",
        "path = \"/content/drive/MyDrive/Project Data/Capstone_Deepfake/train/\"\n",
        "data=[]\n",
        "dir_list = os.listdir(path)\n",
        "for i in dir_list:\n",
        "  frame_path = os.path.join(path,i)\n",
        "  for j in os.listdir(frame_path):\n",
        "    j_path = os.path.join(frame_path,j)\n",
        "    label = 1 if i.startswith(\"real\") else 0\n",
        "    # Append the new row to the DataFrame\n",
        "    data.append([j_path, i, label])\n",
        "# Create a DataFrame from the accumulated data\n",
        "df = pd.DataFrame(data, columns=['filename', 'classname', 'label'])\n",
        "df.to_csv(\"f.csv\",index=False)"
      ],
      "metadata": {
        "id": "9nMh-ZPeZfix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tT-1XrQCx1jC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}